{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MrSwi\\anaconda3\\envs\\projects\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing what is important\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import emoji\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import BertModel\n",
    "##nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT :) \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, freeze=False):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        super(BertModel, self).__init__()\n",
    "        D_in = 32000 # bert_in ?\n",
    "        H, D_out= 16000,2\n",
    "        \n",
    "        self.bert =  AutoModelForMaskedLM.from_pretrained(\"asafaya/bert-mini-arabic\")\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        \n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Loading bert model\n",
    "    @param model_path(str): the bert model path\n",
    "    @return bert_model : a trained bert_model from model_path\n",
    "    @return tokenizer : for preproccing_bert\n",
    "    \"\"\"\n",
    "    # Importing model pretrained\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-mini-arabic\")\n",
    "    bert_model = BertModel(freeze=False)\n",
    "    bert_model.load_state_dict(torch.load(\"bert.pt\"))\n",
    "    return bert_model,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model,tokenizer = load_model(\"bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation\n",
    "\n",
    "# Arabic stop words with nltk\n",
    "stop_words = stopwords.words()\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Shadda\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    '''\n",
    "    text is an arabic string input\n",
    "    \n",
    "    the preprocessed text is returned\n",
    "    '''\n",
    "    \n",
    "    #remove punctuations\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    # remove Tashkeel\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    \n",
    "    #remove longation\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert(data, tokinizer, text_preprocessing_fn = text_preprocessing, MAX_LEN=10):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    # For every sentence...\n",
    "    for i,sent in enumerate(data):\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing_fn(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            padding='max_length',        # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True,     # Return attention mask\n",
    "            truncation = True \n",
    "            )\n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model,text):\n",
    "    \"\"\"\n",
    "    get prediction from model by text\n",
    "    @param model(BertModel):\n",
    "    @param text(str): a text of something to predict\n",
    "    @return pred(int): the catogery of prediction by default (0: negative, 1:positive)\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    text = text_preprocessing(text)\n",
    "    text = np.array([text])\n",
    "    b_input_ids, b_attn_mask = preprocessing_for_bert(text, tokenizer)\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        # Get the predictions\n",
    "        pred = torch.argmax(logits, dim=1).flatten()\n",
    "    return preds.item()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(text):\n",
    "    \n",
    "    pred = get_prediction(bert_model,text)\n",
    "    print(\"Your text: \" , text)\n",
    "    if(pred==0):\n",
    "        print(\"that is a NEGATIVE talk\")\n",
    "    else:\n",
    "        print(\"that is a POSITIVE talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text:   ممكن تقولي يادكتور ، انت ومنهم على شاكلتك ، ماذا فعلتم لاوطانكم ؟ ولَك ياملعون شو اخترعت ...\n",
      "that is a NEGATIVE talk\n"
     ]
    }
   ],
   "source": [
    "display_prediction(\" ممكن تقولي يادكتور ، انت ومنهم على شاكلتك ، ماذا فعلتم لاوطانكم ؟ ولَك ياملعون شو اخترعت ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text:  ستظل مسألة حقوق المرأة مسألة شائكة خاصة بدول الشرق اوسطية التي اغلبها لم تنفك من التص...\n",
      "that is a NEGATIVE talk\n"
     ]
    }
   ],
   "source": [
    "display_prediction(\"ستظل مسألة حقوق المرأة مسألة شائكة خاصة بدول الشرق اوسطية التي اغلبها لم تنفك من التص...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text:  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدولة يعشق ترابها. نحن نحب الإمارات. ومضات من فكر. نصائح ل...\n",
      "that is a NEGATIVE talk\n"
     ]
    }
   ],
   "source": [
    "#FALSE\n",
    "display_prediction(\"أحد أسباب نجاح الإمارات أن كل شخص في هذه الدولة يعشق ترابها. نحن نحب الإمارات. ومضات من فكر. نصائح ل...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text:  السعودية الشرقية القطيف . أعجبني الموقع المتميز بالهدوء وتوفر جميع الخدمات ياس مولعالم فراريووتر وورلد...\n",
      "that is a POSITIVE talk\n"
     ]
    }
   ],
   "source": [
    "display_prediction(\"السعودية الشرقية القطيف . أعجبني الموقع المتميز بالهدوء وتوفر جميع الخدمات ياس مولعالم فراريووتر وورلد...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text:  جيد جدا. أعجبني مطعم السلام نظافته وطهيه لكن أتمنى أن لايقتصر على البوفيه المفتوح بل نريد منه توصيل ...\n",
      "that is a POSITIVE talk\n"
     ]
    }
   ],
   "source": [
    "display_prediction(\"جيد جدا. أعجبني مطعم السلام نظافته وطهيه لكن أتمنى أن لايقتصر على البوفيه المفتوح بل نريد منه توصيل ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
